# -*- coding: utf-8 -*-
"""Training_Class.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Z1mxFQy7f0hPmcL5biOlghYw7t6gY4E
"""

import os
import torch
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn.functional as F
from tqdm import tqdm

from Model_Class_From_the_Scratch import MODEL_From_Scratch
from Model_Class_Transfer_Learning_MobileNet import MobileNet
from Dataset_Class import PyTorch_Classification_Dataset_Class as Dataset

class PyTorch_Classification_Training_Class():
  # 경로, 배치크기, 데이터세트 분할 비율 설정
  def __init__(
      self,
      dataset_dir='./Recycle_Classification_Dataset',
      batch_size=16,
      train_ratio=0.75
      ):

  # 경로 지정 및 데이터세트 다운로드
    if not os.path.isdir(dataset_dir):
      os.system(
          "git clone https://github.com/JinFree/Recycle_Classification_Dataset.git"
      )
      os.system("rm -rf ./Recycle_Classification_Dataset/.git")
      dataset_dir=os.path.join(os.getcwd(),'Recycle_Classification_Dataset')

    # cuda 사용여부에 따른 device변수 설정
    self.USE_CUDA=torch.backends.mps.is_available()
    self.DEVICE=torch.device('mps' if self.USE_CUDA else 'cpu')

    # 전처리 설정
    self.transform=transforms.Compose(
        [
          transforms.Resize(256), # 256*256으로 크기 조정
          transforms.RandomCrop(224), # 랜덤하게 224*224 영역 추출
          transforms.ToTensor(), # 0~255 => 0~1로 변환
          transforms.Normalize( # 정규화
              mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225]
          )
        ]
    )
    dataset=Dataset(dataset_dir=dataset_dir,transform=self.transform)
    dataset.__save_label_map__() #라벨 파일 저장 -> 추론 단계에서 활용
    self.num_classes=dataset.__num_classes__()
    # 데이터 분류
    train_size=int(train_ratio*len(dataset))
    test_size=len(dataset)-train_size
    train_dataset,test_dataset=torch.utils.data.random_split(
        dataset,[train_size,test_size]
    )
    # 데이터 로더 선언 및 초기화
    self.train_loader=torch.utils.data.DataLoader(
        train_dataset,batch_size=batch_size,shuffle=True
    )
    self.test_loader=torch.utils.data.DataLoader(
        test_dataset,batch_size=batch_size,shuffle=False
    )
    # 신경망 모델 및 저장 파일명 선언
    self.model=None
    self.model_str=None

  def prepare_network(self,is_scratch=True): # 직접 구현 / 전이학습 신경망에 따른 신경망 구조 초기화
    if is_scratch: # 직접구현
      self.model=MODEL_From_Scratch(self.num_classes)
      self.model_str='PyTorch_Training_From_Scratch'
    else: # 전이학습
      self.model=MobileNet(self.num_classes)
      self.model_str='PyTorch_Transfer_Learning_MobileNet'
    self.model.to(self.DEVICE)
    self.model_str+='.pt'
    pass

  def training_network(self,learning_rate=0.0001,epochs=10,step_size=3,gamma=0.3): # 하이퍼파라미터 설정 및 실제 훈련 수행
    if self.model is None: #전이학습일 시 (prepare_network가 실행되지 않았다면)
      self.prepare_network(False)
    optimizer=optim.Adam(self.model.parameters(),lr=learning_rate) #최적화 알고리즘
    # 학습 스케줄러 설정 # 학습 스케줄러 설명 참고 : https://resultofeffort.tistory.com/127
    scheduler=optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=gamma)

    acc=0.0
    # 학습
    for epoch in range(1, epochs + 1):
      self.model.train()
      for data,target in tqdm(self.train_loader):
        data,target=data.to(self.DEVICE), target.to(self.DEVICE)
        optimizer.zero_grad() # 미분값 초기화
        output=self.model(data)
        loss=F.cross_entropy(output,target) # 손실함수 계산
        loss.backward() # 역전파
        optimizer.step() # 최적화

      scheduler.step() # 학습률 스케줄러 업데이트

      # 검증
      self.model.eval()

      test_loss=0
      correct=0

      with torch.no_grad(): # autograd엔진을 비활성화 => 메모리 사용량 감소, 순전파 속도 증가
        for data,target in tqdm(self.test_loader):
          data,target=data.to(self.DEVICE),target.to(self.DEVICE)
          output=self.model(data)
          test_loss+=F.cross_entropy(output,target,reduction='sum').item() # 교차 엔트로피로 손실값 계산 후 누적
          pred=output.max(1,keepdim=True)[1] # 가장 확률이 높은 예측값
          correct+=pred.eq(target.view_as(pred)).sum().item()
          # pred.eq(target) : pred 텐서의 각 원소와 x 텐서를 비교하여, 같은 값이면 True, 다르면 False를 반환
          # target.view_as(pred) : target을 pred와 동일한 텐서 모양으로 바꿈.
          
      # 평균 손실값과 정확도 계산
      test_loss/=len(self.test_loader.dataset)
      test_accuracy=100. * correct / len(self.test_loader.dataset)
      print(
          '[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch,test_loss,test_accuracy)
      )
      # 정확도가 좋아지거나 마지막 에포크인 경우 모델 저장
      if acc < test_accuracy or epoch==epochs:
        acc=test_accuracy
        torch.save(self.model.state_dict(),self.model_str)
        print('model saved!')

  
if __name__ == "__main__":
    training_class = PyTorch_Classification_Training_Class()
    training_class.prepare_network(True)
    training_class.training_network()